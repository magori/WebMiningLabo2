\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=4cm]{geometry}
\usepackage{scalerel}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{xspace}
\usepackage{url}
\usepackage{lmodern}
\usepackage{float}
\usepackage{todonotes}
\usepackage{multirow}

\definecolor{myblue}{rgb}{0.33,0.61,0.83}
\definecolor{mygreen}{rgb}{0.39,0.56,0.31}
\definecolor{myorange}{rgb}{0.80,0.56,0.47}

\lstset{
	basicstyle=\ttfamily,
	backgroundcolor=\color{gray!10!white},
	xleftmargin=6pt,
	framexleftmargin=6pt,
	xrightmargin=6pt,
	framexrightmargin=6pt,
	framextopmargin=6pt,
	framexbottommargin=6pt,
	frame=tb,
	framerule=0pt,
	columns=fullflexible,
	breaklines=true,
	tabsize=2,
	%commentstyle=\color{mygreen},
	%keywordstyle=\color{myblue},
	%stringstyle=\color{myorange}
}

\setlength{\headheight}{50pt}
\setlength\parindent{0pt}

\lhead{\includegraphics[scale=0.8]{imgs/logo-mse.png} \vspace{8pt}}

\rhead{\textbf{Data Mining en utilisant RapidMiner} \\
Romain Claret, Dorian Magnin \& Damien Rochat \\
Web Mining 2019}

\cfoot{Page \thepage\ / \pageref{LastPage}}

\pagestyle{fancy}

\begin{document}

\part*{Application de techniques de Data Mining en utilisant le logiciel RapidMiner}
Ce laboratoire a pour objectif d'expérimenter un logiciel de Data Mining, à savoir RapidMiner.
Celui-ci va nous permettre de mettre en place rapidement et simplement diverses tâches de prétraitement, d'appliquer des algorithmes de classification, de clustering, etc. et d'évaluer les résultats obtenus.

\section{Classification de spams}
Ci-dessous, la matrice de confusion résultant de la classification des SMS, avec le classificateur \textit{Naive Bayes}.
\begin{table}[H]
	\centering
	\def\arraystretch{2.0}
	\begin{tabular}{cccl}
	& \textbf{}
	& \multicolumn{2}{c}{\textbf{Prédiction}}\\\cline{3-4} 
	& \multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{\textbf{Non-spam}}\\ \cline{2-4} 
	\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Vérité}}}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	&\multicolumn{1}{c|}{92}
	& \multicolumn{1}{c|}{3}\\ \cline{2-4} 
	\multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Non-spam}}
	& \multicolumn{1}{c|}{38}
	& \multicolumn{1}{c|}{263}\\ \cline{2-4} 
	\end{tabular}
	\caption{Classification des SMS avec un filtrage Bayesien.}
\end{table}
Ce qui donne une accuracy de \textbf{89.65\%}.

\subsubsection*{Dans le bloc "Process Documents from Data" nous n'avons pas mis d'étape de stemming. Est-ce que l'ajout de ce préprocessing a un impact sur les résultats obtenus ?}
Une étape de Stemming Porter (algorithme adapté à la langue anglaise) a été ajoutée après le filtrage des stopwords.
Ceci ne change quasiment pas les résultats obtenus, comme le montre la matrice de confusion suivante :
\begin{table}[H]
	\centering
	\def\arraystretch{2.0}
	\begin{tabular}{cccl}
	& \textbf{}
	& \multicolumn{2}{c}{\textbf{Prédiction}}\\ \cline{3-4} 
	& \multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{\textbf{Non-spam}} \\ \cline{2-4} 
	\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Vérité}}}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{91}
	& \multicolumn{1}{c|}{4}\\ \cline{2-4} 
	\multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Non-spam}}
	& \multicolumn{1}{c|}{38}
	& \multicolumn{1}{c|}{263}               \\ \cline{2-4} 
	\end{tabular}
	\caption{Classification des SMS avec Naive Bayes et Stemming.}
\end{table}

Cette nouvelle étape amène juste le système à se tromper sur un SMS en ne le classant pas comme spam, ajoutant donc un Faux Négatif.

\subsubsection*{Dans l'exemple ci-dessus, nous avons utilisé un classificateur bayésien, veuillez essayer d'autres familles de classificateurs, quel est l'impact sur le résultat obtenu ?}

Tout d'abord, un \textit{Arbre de décision} va avoir une excellente précision lorsqu'il va prédire un SMS comme étant un spam, il ne fait aucune erreur dans ce cas là.
En revanche, il laisse passer beaucoup de spams en ne les détectant pas.


\begin{table}[H]
	\centering
	\def\arraystretch{2.0}
	\begin{tabular}{cccl}
	& \textbf{}
	& \multicolumn{2}{c}{\textbf{Prédiction}}\\ \cline{3-4}
	& \multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{\textbf{Non-spam}} \\ \cline{2-4} 
	\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Vérité}}}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{71}
	& \multicolumn{1}{c|}{24}\\ \cline{2-4} 
	\multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Non-spam}}
	& \multicolumn{1}{c|}{0}
	& \multicolumn{1}{c|}{301}\\ \cline{2-4} 
	\end{tabular}
	\caption{Classification des SMS avec un arbre de décision.}
\end{table}

Malgré tout, l'arbre de décision permet d'arriver à une accuracy de \textbf{93.94\%}, ce qui est sensiblement meilleur qu'un filtrage bayésien.
\\

Nous avons ensuite changé le classificateur pour un \textit{Réseau de neurones}.

\begin{table}[H]
	\centering
	\begin{tabular}{cccl}
	\def\arraystretch{2.0}
	& \textbf{}
	& \multicolumn{2}{c}{\textbf{Prédiction}}\\ \cline{3-4}
	& \multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{\textbf{Non-spam}} \\ \cline{2-4} 
	\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Vérité}}}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{88}
	& \multicolumn{1}{c|}{7}\\ \cline{2-4} 
	\multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Non-spam}}
	& \multicolumn{1}{c|}{4}
	& \multicolumn{1}{c|}{297}\\ \cline{2-4} 
	\end{tabular}
	\caption{Classification des SMS avec un réseau de neurones.}
\end{table}

En ne commettant que 11 erreurs, sur 396 SMS, le réseau de neurones arrive à la meilleure accuracy parmis les classificateurs testés, à savoir \textbf{97.22\%}.

\subsubsection*{Finalement, vous utiliserez la seconde source de données (emails.zip) sur laquelle vous appliquerez le même process. Que constatez-vous en comparant les 2 résultats ?}

Nous avons au préalable eu à préprocesser les données des emails. Dans RapidMiner, nous avons ajouté un bloc permettant de transformer la colonne « spam » en type binomiale et de lui définir le rôle de label (blocs \textit{Numerical to Binomial} et \textit{Set Role}).
\\
De plus, le contenu de la colonne avec le contenu des emails a été tronqué de " Subject : ". Ceci n'affecte évidemment pas le résultat, car il est présent dans chaque élément et n'est donc pas relevant et est ignoré par les algorithmes. Mais ce traitement permet de rendre le modèle réutilisable.
\\\\
Avec un classificateur \textit{Naive Bayes}, nous arrivons à la matrice de confusion suivante :


\begin{table}[H]
	\centering
	\begin{tabular}{cccl}
	\def\arraystretch{2.0}
	& \textbf{}
	& \multicolumn{2}{c}{\textbf{Prédiction}}\\ \cline{3-4}
	& \multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{\textbf{Non-spam}} \\ \cline{2-4}
	\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Vérité}}}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{340}
	& \multicolumn{1}{c|}{11}\\ \cline{2-4} 
	\multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Non-spam}}
	& \multicolumn{1}{c|}{38}
	& \multicolumn{1}{c|}{1249}\\ \cline{2-4} 
	
	\end{tabular}
	\caption{Classification des emails avec un filtrage Bayesien.}
\end{table}

Avec une accuracy de \textbf{97.01\%}, il s'agit d'un très bon résultat.
Ajouter une étape de stemming n'améliore pas non plus le résultat sur ce type de données.
\\

Nous avons également essayé d'utiliser un arbre de décision avec les emails.
Celui-ci nous a permis d'arriver à une accuracy de \textbf{86.81\%}, avec beaucoup de Faux Négatifs, ce qui est bien moins efficace.
Un arbre de décision est de moins en moins efficace plus la taille et la complexité des données augmentent.

\begin{table}[H]
	\centering
	\begin{tabular}{cccl}
	\def\arraystretch{2.0}
	& \textbf{}
	& \multicolumn{2}{c}{\textbf{Prédiction}}\\ \cline{3-4} 
	& \multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{\textbf{Non-spam}} \\ \cline{2-4} 
	\multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Vérité}}}
	& \multicolumn{1}{c|}{\textbf{Spam}}
	& \multicolumn{1}{c|}{166}
	& \multicolumn{1}{c|}{212}\\ \cline{2-4} 
	\multicolumn{1}{c|}{}
	& \multicolumn{1}{c|}{\textbf{Non-spam}} & \multicolumn{1}{c|}{4}
	& \multicolumn{1}{c|}{1256}\\ \cline{2-4} 
	\end{tabular}
	\caption{Classification des emails avec un arbre de décision.}
\end{table}

\section{Market basket analysis}

Pour la création des fichiers CSV utilisés pour la génération de règles d'associations, un nettoyage des données a été fait.
\\
Les lignes avec des données vides, comme par exemple le nom du produit sont filtrées.
Il en est de même si la quantité est plus petite que 0.
Un programme a été implémenté afin de détecter et filtrer les lignes avec des éventuels noms de produit incohérents.
\\
\\\\
Voici une liste des noms incohérents trouvés :
\textit{wet pallet,sold in set?,wet damaged,faulty,posy candy bag,michel oops,wet/mouldy,
lost,dagamed,daisy notebook,fba,taig adjust,water damage,ribbons purse,?display?,found in w/hse,damaged stock,
samples,
mixed up,???missing,breakages,chilli lights,dotcom set,re-adjustment,packing charge,amazon sales,?,
mix up with c,owl doorstop,stock check,mia,wrap folk art,carriage,damages,?lost,john lewis,found box,20713,show samples,damages wax,website fixed,jumbo bag owls,wet boxes,frog candle,found,given away,mouldy,???,broken,
wrong code,damages?,display,wet,bunny egg box,polkadot pen,?missing,dotcom,amazon adjust,damaged,returned,
toybox  wrap,smashed,?sold as sets?,showroom,led tea lights,wet/rusty,missing?,wrong barcode,lost in space,
crushed ctn,popcorn holder,dotcom sales,lost??,sold as 1,bingo set,thrown away.,crushed boxes,test,check,crushed,
wet?,mailout,amazon,rain poncho,adjust,ebay,adjustment,spotty bunting,wet rusty,cracked,sale error,???lost,
water damaged,missing,garage key fob,dotcomstock,dotcom adjust,sold as 22467,??,dotcom postage,jumbo bag toys,
shoe shine box,?? missing,on cargo order,wrong code?,check?,label mix up,postage,wrap carousel,can't find,
\\\\
De plus, chaque donnée de colonne est systématiquement trimée pour éviter tout problème et pour faciliter la suite du traitement. 
Voici quelques statistiques calculées lors du filtrage :
\\\\
wrongly marked,retrospot lamp,thrown away,counted,????missing,cordial jug}
\begin{itemize}
	\item Nombre de lignes dans le fichier : 541'909
	\item Nombre de lignes après nettoyage : 397'924
	\item Nombre de produits : 3'639
\end{itemize}

\vspace{6pt}
Le programme a donc retiré 143'985 lignes.
\\\\
Un autre programme a été implémenté pour standardiser la description des produits en la liant avec le numéro du produit et celle qui est la plus utilisée, dans le cas un produit aurait plusieurs descriptions. \\
Pour voir une partie de l'algorithme, il faut regarder la fonction \textit{Main.resolveProductDescription()} dans le code Java fourni en annexe.
\\\\
Ci-dessous, d'autres informations que nous calculons lors de la création des nouveaux fichiers CSV.
\\
Création du fichier par pays (permets de tester rapidement le code) :
\begin{itemize}
	\item Nombre de lignes dans le nouveau fichier byCountry.csv : 37
	\item Durée du traitement: 00:01.625
\end{itemize}
\vspace{6pt}

Création du fichier par client :
\begin{itemize}
	\item Nombre de lignes dans le nouveau fichier byCustomer.csv : 4'339
	\item Durée du traitement: 01:44.361
\end{itemize}

\vspace{6pt}

Création du fichier par facture :
\begin{itemize}
	\item Nombre de lignes dans le nouveau fichier byInvoice.csv : 18'536
	\item Durée du traitement: 07:26.901
\end{itemize}

\vspace{6pt}

Afin de pouvoir générer ces données, nous avons utilisé du multi-threading ce qui nous a permis d'améliorer considérablement le temps nécessaire à la création des fichiers.
\\\\
Pour lire le fichier, nous avons dû en créer un nouveau et copiant et collant son contenu. Nous pensons qu'il doit y avoir un problème d'encodage. 
\\\\
Pour tester le programme, il suffit de lancer la commande \textit{mvn clean install}, de modifier le fichier \textit{application.properties} avec l'emplacement des fichiers de base et de destination.
\\\\
La création de ces fichiers n'est pas simple et nous a pris beaucoup de temps. Par exemple, nous pourrions encore améliorer la génération, en tenant compte des produits retournés.
Il serait aussi bien d'avoir un meilleur descriptif de ces données.

\subsubsection*{Constatez-vous des différences dans les règles d'associations obtenues entre les 2 regroupements différents (par facture/par client) ? Veuillez commenter vos résultats.}

\subsubsection*{Est-il possible de générer une/des autre/s colonne/s à partir des données initiales qui produisent des règles intéressantes ?}
\section{Market basket analysis}
\subsection{Questions about association rules}
\textbf{Constatez-vous des différences dans les règles d'associations obtenues entre les 2 regroupements différents (par facture/par client) ? Veuillez commenter vos résultats.}
\\\\
\textbf{Est-il possible de générer une/des autre/s colonne/s à partir des données initiales qui produisent des règles intéressantes ?}

\section{Utilisation d'un WordNet sur des commentaires d’utilisateurs}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_full_process}
	\caption{Processus complet: WordNet sur 3000 commentaires }
	\label{fig:3_full_process}
\end{figure}

Dans le cadre de cette 3e partie, nous avons mis en place un processus capable de comparer des commentaires sous format texte fourni avec un étiquetage du sentiment (Positif, Négatif, et Neutre), avec un algorithme de prédiction capable d'extraire le sentiment d'un texte basé sur le dictionnaire WordNet. Pour simplifier la comparaison, nous avons ajouté un attribue qui vérifie que le sentiment source est le même que le sentiment prédit (matching).

\subsection{Questions sur les règles d'association}

\textbf{Commentez les résultats obtenus par rapport aux étiquettes existantes sur le dataset.}
\textbf{Quelle est l'influence des différentes étapes de "text processing" sur le résultat que vous obtenez ?}

\subsubsection{Process Documents from Data sur touts les éléments communs}
Dans le cas où on utilise tout les éléments courant pour prétraiter le text fourni à la fonction "Extract Sentiment" (Fig. \ref{fig:3_processing_documents_full}), nous obtenons un résultat à 46\% correct.
C'est à dire:
	
\begin{itemize}
	\item tokenisation
	\item transformation en caractères minuscules
	\item suppression des stop words
	\item filtre sur la longueur des tokens
	\item stemming (particularité nous utilisons le stemming basé sur le WordNet)
\end{itemize}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_full}
	\caption{Process Documents from Data with all elements}
	\label{fig:3_processing_documents_full}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_full_results}
	\caption{Results of the Process Documents from Data with all elements}
	\label{fig:3_processing_documents_full_results}
\end{figure}


\subsubsection{Process Documents from Data uniquement avec le module d'extraction du sentiment WordNet}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token_stopword_transform_tokens}
	\caption{Process Documents from Data with only the sentiment extractor from WordNet}
	\label{fig:3_processing_documents_no_stem_filter_token_stopword_transform_tokens}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token_stopword_transform_tokens_results}
	\caption{Results of the Process Documents from Data with only the sentiment extractor from WordNet}
	\label{fig:3_processing_documents_no_stem_filter_token_stopword_transform_tokens_results}
\end{figure}


\subsubsection{Process Documents from Data composé de la tokenisation}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token_stopword_transform}
	\caption{Process Documents from Data with tokenization}
	\label{fig:3_processing_documents_no_stem_filter_token_stopword_transform}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token_stopword_transform_results}
	\caption{Resulats of the Process Documents from Data with tokenization}
	\label{fig:3_processing_documents_no_stem_filter_token_stopword_transform_results}
\end{figure}


\subsubsection{Process Documents from Data composé de la tokenisation ainsi que de la transformation en caractères minuscules}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token_stopword}
	\caption{Process Documents from Data with tokenization and low character filter}
	\label{fig:3_processing_documents_full}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token_stopword_results}
	\caption{Results of the Process Documents from Data with tokenization and low character filter}
	\label{fig:3_processing_documents_no_stem_filter_token_stopword_results}
\end{figure}


\subsubsection{Process Documents from Data composé de la tokenisation, la transformation en caractères minuscules, et la suppression des stop words}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token}
	\caption{Process Documents from Data with the tokenizion, the low cases, and stopword filter}
	\label{fig:3_processing_documents_no_stem_filter_token}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_filter_token_results}
	\caption{Results on the Process Documents from Data with the tokenizion, the low cases, and stopword filter}
	\label{fig:3_processing_documents_no_stem_filter_token_results}
\end{figure}


\subsubsection{Process Documents from Data composé de la tokenisation, la transformation en caractères minuscules, la suppression des stop words, et un filtre sur la longueur des tokens}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem}
	\caption{Process Documents from Data with all elements expect stemming}
	\label{fig:3_processing_documents_no_stem}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_no_stem_results}
	\caption{Results on the Process Documents from Data with all elements expect stemming}
	\label{fig:3_processing_documents_no_stem_results}
\end{figure}
	
	

\subsubsection{Seuil par défaut du threshold du module d'extraction de sentiment de WordNet à 0.05}
Les résultats sont basés sur la topologie complète (Fig.\ref{fig:3_processing_documents_full})
\begin{figure}[H]
\begin{center}
	\includegraphics[width=\linewidth/3]{imgs/part_3/3_processing_documents_full_0_05}
	\caption{Extract Sentiment Threshold at 0.05}
	\label{fig:3_processing_documents_full_0_05}
\end{center}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_full_0_05_results}
	\caption{Result of the extracted sentiment with the threshold at 0.05}
	\label{fig:3_processing_documents_full_0_05_results}
\end{figure}



\subsubsection{Modification du threshold du module d'extraction de sentiment de WordNet à 0.01}
\begin{figure}[H]
\begin{center}
	\includegraphics[width=\linewidth/3]{imgs/part_3/3_processing_documents_full_0_01}
	\caption{Extract Sentiment Threshold at 0.05}
	\label{fig:3_processing_documents_full_0_01}
\end{center}
\end{figure}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_full_0_01_results}
	\caption{Result of the extracted sentiment with the threshold at 0.01}
	\label{fig:3_processing_documents_full_0_01_results}
\end{figure}

\subsubsection{Modification du threshold du module d'extraction de sentiment de WordNet à 0.5}
\begin{figure}[H]
\begin{center}
	\caption{Extract Sentiment Threshold at 0.5}
	\label{fig:3_processing_documents_full_0_5}
	\includegraphics[width=\linewidth/3]{imgs/part_3/3_processing_documents_full_0_5}
\end{center}
\end{figure}
\begin{figure}[H]
\begin{center}
	\includegraphics[width=\linewidth]{imgs/part_3/3_processing_documents_full_0_5_results}
	\caption{Result of the extracted sentiment with the threshold at 0.5}
	\label{fig:3_processing_documents_full_0_5_results}
\end{center}
\end{figure}

\section{Conclusion}

\end{document}

%\begin{center}
%	\includegraphics[scale=0.5]{imgs/architecture.png}
%\end{center}

%\begin{lstlisting}[language=sh]
%	$ gradle run
%\end{lstlisting}

%\vspace{6pt}

%\begin{itemize}  
%\item item
%\end{itemize}


%\begin{figure}[H]
%	\includegraphics[width=\linewidth]{imgs/title}
%	\caption{Wikipedia Title}
%	\label{fig:title}
%\end{figure}

